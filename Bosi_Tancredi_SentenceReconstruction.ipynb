{"cells":[{"cell_type":"markdown","id":"19b71612","metadata":{"id":"19b71612","papermill":{"duration":0.010299,"end_time":"2024-06-11T18:23:24.650085","exception":false,"start_time":"2024-06-11T18:23:24.639786","status":"completed"},"tags":[]},"source":["# Name: Tancredi Bosi\n","# ID number: 0001121897\n","\n","### Submission for the Deep Learning project - 14/06/2024"]},{"cell_type":"markdown","id":"20810341","metadata":{"id":"20810341","papermill":{"duration":0.009882,"end_time":"2024-06-11T18:23:24.669958","exception":false,"start_time":"2024-06-11T18:23:24.660076","status":"completed"},"tags":[]},"source":["# Sentence Reconstruction"]},{"cell_type":"markdown","id":"04716c8f","metadata":{"id":"04716c8f","papermill":{"duration":0.009816,"end_time":"2024-06-11T18:23:24.690065","exception":false,"start_time":"2024-06-11T18:23:24.680249","status":"completed"},"tags":[]},"source":["The purpose of this project is to take in input a sequence of words corresponding to a random permutation of a given english sentence, and reconstruct the original sentence.\n","\n","The output can be either produced in a single shot, or through an iterative (autoregressive) loop generating a single token at a time.\n","\n","\n","CONSTRAINTS:\n","* No pretrained model can be used.\n","* The neural network models should have less the 20M parameters.\n","* No postprocessing should be done (e.g. no beamsearch)\n","* You cannot use additional training data.\n","\n","\n","BONUS PARAMETERS:\n","\n","A bonus of 0-2 points will be attributed to incentivate the adoption of models with a low number of parameters."]},{"cell_type":"markdown","id":"22d9d925","metadata":{"id":"22d9d925","papermill":{"duration":0.009706,"end_time":"2024-06-11T18:23:24.710128","exception":false,"start_time":"2024-06-11T18:23:24.700422","status":"completed"},"tags":[]},"source":["# Dataset\n","\n","The dataset is composed by sentences taken from the generics_kb dataset of hugging face. We restricted the vocabolary to the 10K most frequent words, and only took sentences making use of this vocabulary."]},{"cell_type":"code","execution_count":null,"id":"87dae8f9","metadata":{"execution":{"iopub.execute_input":"2024-06-11T18:23:24.732612Z","iopub.status.busy":"2024-06-11T18:23:24.731676Z","iopub.status.idle":"2024-06-11T18:23:51.550292Z","shell.execute_reply":"2024-06-11T18:23:51.549372Z"},"id":"87dae8f9","outputId":"3d654165-ac8f-4813-f2e5-0feb30f4c6e4","papermill":{"duration":26.832607,"end_time":"2024-06-11T18:23:51.552703","exception":false,"start_time":"2024-06-11T18:23:24.720096","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.19.2)\r\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.13.1)\r\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\r\n","Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (14.0.2)\r\n","Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\r\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\r\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.1)\r\n","Requirement already satisfied: requests>=2.32.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\r\n","Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\r\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\r\n","Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\r\n","Requirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets) (2024.3.1)\r\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\r\n","Requirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.23.2)\r\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\r\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\r\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\r\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\r\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\r\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\r\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\r\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\r\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets) (4.9.0)\r\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\r\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.1->datasets) (3.3.2)\r\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.1->datasets) (3.6)\r\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.1->datasets) (1.26.18)\r\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.1->datasets) (2024.2.2)\r\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\r\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\r\n","Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\r\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\r\n","Requirement already satisfied: keras in /opt/conda/lib/python3.10/site-packages (3.3.3)\r\n","Requirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from keras) (1.4.0)\r\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from keras) (1.26.4)\r\n","Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras) (13.7.0)\r\n","Requirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras) (0.0.8)\r\n","Requirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from keras) (3.10.0)\r\n","Requirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras) (0.11.0)\r\n","Requirement already satisfied: ml-dtypes in /opt/conda/lib/python3.10/site-packages (from keras) (0.2.0)\r\n","Requirement already satisfied: typing-extensions>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from optree->keras) (4.9.0)\r\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras) (3.0.0)\r\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras) (2.17.2)\r\n","Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\r\n"]}],"source":["!pip install datasets\n","!pip install --upgrade keras"]},{"cell_type":"markdown","id":"4efcb1a7","metadata":{"id":"4efcb1a7","papermill":{"duration":0.011675,"end_time":"2024-06-11T18:23:51.575619","exception":false,"start_time":"2024-06-11T18:23:51.563944","status":"completed"},"tags":[]},"source":["# Import the libraries and set the seed"]},{"cell_type":"code","execution_count":null,"id":"60a98b71","metadata":{"execution":{"iopub.execute_input":"2024-06-11T18:23:51.599635Z","iopub.status.busy":"2024-06-11T18:23:51.598768Z","iopub.status.idle":"2024-06-11T18:24:05.651148Z","shell.execute_reply":"2024-06-11T18:24:05.650361Z"},"id":"60a98b71","outputId":"9171c54f-9c64-41e9-a592-3835feeb56df","papermill":{"duration":14.067279,"end_time":"2024-06-11T18:24:05.653567","exception":false,"start_time":"2024-06-11T18:23:51.586288","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-06-11 18:23:55.322896: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-06-11 18:23:55.323044: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-06-11 18:23:55.460437: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["from datasets import load_dataset\n","import tensorflow as tf\n","import numpy as np\n","import keras\n","import keras.layers as layers\n","import keras.ops as ops\n","from difflib import SequenceMatcher\n","from keras.layers import TextVectorization, MultiHeadAttention, LayerNormalization\n","from tensorflow.keras.utils import Sequence\n","from keras.callbacks import EarlyStopping\n","import matplotlib.pyplot as plt\n","import os\n","import datetime\n","import random\n","\n","seed = 42\n","np.random.seed(seed)\n","tf.random.set_seed(seed)\n","random.seed(seed)"]},{"cell_type":"markdown","id":"bf2d1f6e","metadata":{"id":"bf2d1f6e","papermill":{"duration":0.011283,"end_time":"2024-06-11T18:24:05.676464","exception":false,"start_time":"2024-06-11T18:24:05.665181","status":"completed"},"tags":[]},"source":["# Dataset"]},{"cell_type":"code","execution_count":null,"id":"bcc16a0a","metadata":{"execution":{"iopub.execute_input":"2024-06-11T18:24:05.700466Z","iopub.status.busy":"2024-06-11T18:24:05.699789Z","iopub.status.idle":"2024-06-11T18:24:05.708126Z","shell.execute_reply":"2024-06-11T18:24:05.707363Z"},"id":"bcc16a0a","papermill":{"duration":0.022744,"end_time":"2024-06-11T18:24:05.710190","exception":false,"start_time":"2024-06-11T18:24:05.687446","status":"completed"},"tags":[]},"outputs":[],"source":["# Given TextDetokenizer\n","class TextDetokenizer:\n","    def __init__(self, vectorize_layer):\n","        self.vectorize_layer = vectorize_layer\n","        vocab = self.vectorize_layer.get_vocabulary()\n","        self.index_to_word = {index: word for index, word in enumerate(vocab)}\n","\n","    def __detokenize_tokens(self, tokens):\n","        def check_token(t):\n","            if t == 3:\n","                s=\"<start>\"\n","            elif t == 2:\n","                s=\"<end>\"\n","            elif t == 7:\n","                s=\"<comma>\"\n","            else:\n","                s=self.index_to_word.get(t, '[UNK]')\n","            return s\n","        return ' '.join([ check_token(token) for token in tokens if token != 0])\n","\n","    def __call__(self, batch_tokens):\n","        return [self.__detokenize_tokens(tokens) for tokens in batch_tokens]"]},{"cell_type":"code","execution_count":null,"id":"be40262d","metadata":{"execution":{"iopub.execute_input":"2024-06-11T18:24:05.735127Z","iopub.status.busy":"2024-06-11T18:24:05.734760Z","iopub.status.idle":"2024-06-11T18:24:05.744960Z","shell.execute_reply":"2024-06-11T18:24:05.743979Z"},"id":"be40262d","papermill":{"duration":0.02556,"end_time":"2024-06-11T18:24:05.747074","exception":false,"start_time":"2024-06-11T18:24:05.721514","status":"completed"},"tags":[]},"outputs":[],"source":["# Given DataGenerator\n","class DataGenerator(Sequence):\n","    def __init__(self, data, batch_size=128, shuffle=True, seed=42):\n","\n","        self.data = data\n","        self.batch_size = batch_size\n","        self.shuffle = shuffle\n","        self.seed = seed\n","        self.on_epoch_end()\n","\n","    def __len__(self):\n","        return int(np.floor(len(self.data) / self.batch_size))\n","\n","    def __getitem__(self, index):\n","        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n","\n","        data_batch = np.array([self.data[k] for k in indexes])\n","        #copy of ordered sequences\n","        result = np.copy(data_batch)\n","        #shuffle only the relevant positions for each batch\n","        for i in range(data_batch.shape[0]):\n","          np.random.shuffle(data_batch[i,1:data_batch[i].argmin() - 1])\n","\n","        return data_batch , result\n","\n","    def on_epoch_end(self):\n","        self.indexes = np.arange(len(self.data))\n","        if self.shuffle:\n","            if self.seed is not None:\n","              np.random.seed(self.seed)\n","            np.random.shuffle(self.indexes)"]},{"cell_type":"markdown","id":"ba5e2414","metadata":{"id":"ba5e2414","papermill":{"duration":0.011105,"end_time":"2024-06-11T18:24:05.769704","exception":false,"start_time":"2024-06-11T18:24:05.758599","status":"completed"},"tags":[]},"source":["#### Download the dataset"]},{"cell_type":"code","execution_count":null,"id":"134613d3","metadata":{"execution":{"iopub.execute_input":"2024-06-11T18:24:05.795989Z","iopub.status.busy":"2024-06-11T18:24:05.795631Z","iopub.status.idle":"2024-06-11T18:26:58.005198Z","shell.execute_reply":"2024-06-11T18:26:58.004145Z"},"id":"134613d3","outputId":"892bc171-2167-4cae-d26d-bc26a8d605ce","papermill":{"duration":172.225074,"end_time":"2024-06-11T18:26:58.007652","exception":false,"start_time":"2024-06-11T18:24:05.782578","status":"completed"},"tags":[],"colab":{"referenced_widgets":["d496e3dfc8204dfe9bedad9956c3c987","dde050924b7a4170a839963599e732af","eae52282de9840a1a32723a1b79e4678","4bdefa7888f24fcea8affc40c8eed02a","5784f61dd1b04670912a277da0382a22"]}},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d496e3dfc8204dfe9bedad9956c3c987","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/8.64k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dde050924b7a4170a839963599e732af","version_major":2,"version_minor":0},"text/plain":["Downloading readme:   0%|          | 0.00/11.9k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"eae52282de9840a1a32723a1b79e4678","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/27.1M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4bdefa7888f24fcea8affc40c8eed02a","version_major":2,"version_minor":0},"text/plain":["Generating train split:   0%|          | 0/1020868 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5784f61dd1b04670912a277da0382a22","version_major":2,"version_minor":0},"text/plain":["Filter:   0%|          | 0/1020868 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Download the dataset\n","ds = load_dataset('generics_kb', trust_remote_code=True)['train']\n","\n","# Filter the rows with lenght greater than 8\n","ds = ds.filter(lambda row: len(row[\"generic_sentence\"].split(\" \")) > 8)\n","\n","# Add a start and an end token and replace ',' with a token\n","corpus = ['<start> ' + row['generic_sentence'].replace(\",\", \" <comma>\") + ' <end>' for row in ds]\n","corpus = np.array(corpus)\n","\n","# Create a tokenizer\n","tokenizer = TextVectorization(max_tokens=10000, standardize=\"lower_and_strip_punctuation\", encoding=\"utf-8\", )\n","tokenizer.adapt(corpus)\n","\n","# Create a detokenizer\n","detokenizer = TextDetokenizer(tokenizer)\n","sentences = tokenizer(corpus).numpy()\n","\n","# Remove from corpus the sentences where any unknown word appears\n","mask = np.sum((sentences == 1), axis=1) >= 1\n","original_data = np.delete(sentences, mask, axis=0)\n","\n","# Shuffle the all data with a random permutation of training and test set\n","shuffled_indices = np.random.permutation(len(original_data))\n","shuffled_data = original_data[shuffled_indices]"]},{"cell_type":"markdown","id":"a64f2627","metadata":{"id":"a64f2627","papermill":{"duration":0.011366,"end_time":"2024-06-11T18:26:58.031113","exception":false,"start_time":"2024-06-11T18:26:58.019747","status":"completed"},"tags":[]},"source":["#### Split the dataset"]},{"cell_type":"code","execution_count":null,"id":"996120bf","metadata":{"execution":{"iopub.execute_input":"2024-06-11T18:26:58.056108Z","iopub.status.busy":"2024-06-11T18:26:58.055340Z","iopub.status.idle":"2024-06-11T18:26:59.397137Z","shell.execute_reply":"2024-06-11T18:26:59.396347Z"},"id":"996120bf","papermill":{"duration":1.356611,"end_time":"2024-06-11T18:26:59.399499","exception":false,"start_time":"2024-06-11T18:26:58.042888","status":"completed"},"tags":[]},"outputs":[],"source":["# Train set\n","train_generator = DataGenerator(shuffled_data[:220000], 220000)\n","Xtrain, ytrain = train_generator.__getitem__(0)\n","labels = ytrain"]},{"cell_type":"markdown","id":"14dc02f0","metadata":{"id":"14dc02f0","papermill":{"duration":0.011291,"end_time":"2024-06-11T18:26:59.422545","exception":false,"start_time":"2024-06-11T18:26:59.411254","status":"completed"},"tags":[]},"source":["# Set the DropOut rate"]},{"cell_type":"code","execution_count":null,"id":"db941e32","metadata":{"execution":{"iopub.execute_input":"2024-06-11T18:26:59.448229Z","iopub.status.busy":"2024-06-11T18:26:59.447469Z","iopub.status.idle":"2024-06-11T18:26:59.451675Z","shell.execute_reply":"2024-06-11T18:26:59.450732Z"},"id":"db941e32","papermill":{"duration":0.018738,"end_time":"2024-06-11T18:26:59.453708","exception":false,"start_time":"2024-06-11T18:26:59.434970","status":"completed"},"tags":[]},"outputs":[],"source":["dropout_rate = 0.1"]},{"cell_type":"markdown","id":"79afc676","metadata":{"id":"79afc676","papermill":{"duration":0.011393,"end_time":"2024-06-11T18:26:59.476807","exception":false,"start_time":"2024-06-11T18:26:59.465414","status":"completed"},"tags":[]},"source":["# Model class\n","I used a Transformer, with Ecoder and Decoder exploiting the self-attention layers. This approach is the most used I think being the main architecture for text processing."]},{"cell_type":"code","execution_count":null,"id":"99bfdb0c","metadata":{"execution":{"iopub.execute_input":"2024-06-11T18:26:59.502259Z","iopub.status.busy":"2024-06-11T18:26:59.501916Z","iopub.status.idle":"2024-06-11T18:26:59.530542Z","shell.execute_reply":"2024-06-11T18:26:59.529603Z"},"id":"99bfdb0c","papermill":{"duration":0.044122,"end_time":"2024-06-11T18:26:59.532640","exception":false,"start_time":"2024-06-11T18:26:59.488518","status":"completed"},"tags":[]},"outputs":[],"source":["class TransformerBlock(layers.Layer):\n","    def __init__(self, embed_dim, num_heads, ff_dim, rate=dropout_rate):\n","        super().__init__()\n","        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n","        self.ffn = tf.keras.Sequential(\n","            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n","        )\n","        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n","        self.dropout1 = layers.Dropout(rate)\n","        self.dropout2 = layers.Dropout(rate)\n","\n","    def call(self, inputs, training=True):\n","        attn_output = self.att(inputs, inputs, inputs) # Multi head attention where Key, Value and Query are all the same\n","        attn_output = self.dropout1(attn_output, training=training) # We add a dropout to reduce overfitting\n","        out1 = self.layernorm1(inputs + attn_output) # We add a residual connection and layernorm the result\n","        ffn_output = self.ffn(out1) # Feedforward network\n","        ffn_output = self.dropout2(ffn_output, training=training) # a second dropout\n","        return self.layernorm2(out1 + ffn_output) # a second residual connection\n","\n","class TokenAndPositionEmbedding(layers.Layer):\n","    def __init__(self, maxlen, vocab_size, embed_dim):\n","        super().__init__()\n","        # The embedding layer turns positive integers into dense vectors,\n","        # so that words with similar meaning are close to each other\n","        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n","        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n","\n","    def call(self, x):\n","        # get the number of tokens\n","        maxlen = tf.shape(x)[-1]\n","        # get all positions in order\n","        positions = tf.range(start=0, limit=maxlen, delta=1)\n","        # then get the embedded positions\n","        positions = self.pos_emb(positions)\n","        # compute the token embeddings\n","        x = self.token_emb(x)\n","        # return the embedded tokens + the positions\n","        return x + positions\n","\n","class TransformerEncoder(layers.Layer):\n","    def __init__(self, num_layers, embed_dim, num_heads, ff_dim, input_vocab_size, maximum_position_encoding, rate=dropout_rate):\n","        super().__init__()\n","        self.num_layers = num_layers\n","        self.embed_dim = embed_dim\n","        self.token_emb = TokenAndPositionEmbedding(maxlen=maximum_position_encoding, vocab_size=input_vocab_size, embed_dim=embed_dim)\n","        self.enc_layers = [TransformerBlock(embed_dim, num_heads, ff_dim, rate) for _ in range(num_layers)]\n","        self.dropout = layers.Dropout(rate)\n","\n","    def call(self, inputs, training=True):\n","        x = self.token_emb(inputs)\n","        for i in range(self.num_layers):\n","            x = self.enc_layers[i](x, training=training)\n","        return self.dropout(x, training=training)\n","\n","class TransformerDecoderBlock(layers.Layer):\n","    def __init__(self, embed_dim, num_heads, ff_dim, rate=dropout_rate):\n","        super().__init__()\n","        self.att1 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n","        self.att2 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n","        self.ffn = tf.keras.Sequential(\n","            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n","        )\n","        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm3 = layers.LayerNormalization(epsilon=1e-6)\n","        self.dropout1 = layers.Dropout(rate)\n","        self.dropout2 = layers.Dropout(rate)\n","\n","    def call(self, inputs, enc_output, training=True):\n","        attn_output = self.att2(inputs, inputs, inputs, use_causal_mask=True) # Multi head attention where Key, Value and Query are all the same\n","        attn_output = self.dropout1(attn_output, training=training) # We add a dropout to reduce overfitting\n","        out1 = self.layernorm1(inputs + attn_output) # We add a residual connection and layernorm the result\n","        attn_output_2 = self.att1(out1,enc_output, enc_output)\n","        out2= self.layernorm2(attn_output_2 + out1)\n","        ffn_output = self.ffn(out2) # Feedforward network\n","        ffn_output = self.dropout2(ffn_output, training=training) # a second dropout\n","        return self.layernorm3(out2 + ffn_output) # a second residual connection\n","\n","class TransformerDecoder(layers.Layer):\n","    def __init__(self, num_layers, embed_dim, num_heads, ff_dim, target_vocab_size, maximum_position_encoding, rate=dropout_rate):\n","        super().__init__()\n","        self.num_layers = num_layers\n","        self.embed_dim = embed_dim\n","        self.token_emb = TokenAndPositionEmbedding(maxlen=maximum_position_encoding, vocab_size=target_vocab_size, embed_dim=embed_dim)\n","        self.dec_layers = [TransformerDecoderBlock(embed_dim, num_heads, ff_dim, rate) for _ in range(num_layers)]\n","        self.dropout = layers.Dropout(rate)\n","\n","    def call(self, inputs, enc_output, training=True):\n","        attention_weights = {}\n","        x = self.token_emb(inputs)\n","        for i in range(self.num_layers):\n","            x = self.dec_layers[i](x, enc_output, training=training)\n","        return self.dropout(x, training=training)\n","\n","class Transformer(keras.Model):\n","    def __init__(self, num_layers, embed_dim, num_heads, ff_dim, input_vocab_size, target_vocab_size, pe_input, pe_target, rate=dropout_rate):\n","        super().__init__()\n","        self.encoder = TransformerEncoder(num_layers, embed_dim, num_heads, ff_dim, input_vocab_size, pe_input, rate)\n","        self.decoder = TransformerDecoder(num_layers, embed_dim, num_heads, ff_dim, target_vocab_size, pe_target, rate)\n","        self.final_layer = layers.Dense(target_vocab_size)\n","\n","    def call(self, inputs,training=True):\n","        x,y=inputs\n","        enc_output = self.encoder(x, training=training)\n","        dec_output = self.decoder(y, enc_output, training=training)\n","        final_output = self.final_layer(dec_output)\n","        return final_output"]},{"cell_type":"markdown","id":"59524a17","metadata":{"id":"59524a17","papermill":{"duration":0.011338,"end_time":"2024-06-11T18:26:59.556141","exception":false,"start_time":"2024-06-11T18:26:59.544803","status":"completed"},"tags":[]},"source":["# Set the parameters and create the model\n","Define the model to use with the tuned hyperparameters.\n","The hyperparameters chosen are obtained through a sequence of trials of training. Hyperparameters:\n","- number of encoder layers: 6\n","- number of decoder layers: 6\n","- number of heads: 8\n","- embedding size: 128\n","- dimension of FNN layers: 256\n","\n","Using a network with 6 encorders and 6 decoders was the choice that made my network work better. Also the number of heads increased a lot the performances, so I set it to 8. Increasing the dimension of the embeddings would improve a lot the performances, but it would also increase the dimension of the parameters to train too much; therefore I decided to keep it to 128. The dimension of the FNN layers does not increase too much the dimension of the model, so I chose a solid 256.\n","\n","### Performances\n","With these hyperparameters I obtained a **score of 0.5007 on 5k sentences** of the shuffled test set. This result is therefore obtained with a model that has **14.1 million parameters**.\n","\n","### Other architectures\n","Increasing the model dimensions was still improving the score, reaching 0.52 with a 19.9M parameters model, but I decided to prefer a **smaller and faster model** to make a more reasonable choice for a real case scenario, where 5 million less parameters can make the difference."]},{"cell_type":"code","execution_count":null,"id":"708df1f9","metadata":{"execution":{"iopub.execute_input":"2024-06-11T18:26:59.580410Z","iopub.status.busy":"2024-06-11T18:26:59.580036Z","iopub.status.idle":"2024-06-11T18:26:59.753070Z","shell.execute_reply":"2024-06-11T18:26:59.752255Z"},"id":"708df1f9","papermill":{"duration":0.187677,"end_time":"2024-06-11T18:26:59.755219","exception":false,"start_time":"2024-06-11T18:26:59.567542","status":"completed"},"tags":[]},"outputs":[],"source":["# Number of encoders and decoders\n","num_layers = 6\n","\n","# Dimension of the embedding\n","embed_dim = 128\n","\n","# Number of heads\n","num_heads = 8\n","\n","# Dimension of the FNN layers\n","ff_dim = 256\n","\n","# Size of input and output vocabularies\n","input_vocab_size = 10000\n","target_vocab_size = 10000\n","\n","# Maximum position encodings\n","pe_input = 28\n","pe_target = 28\n","\n","# Create the transformer model\n","model = Transformer(num_layers, embed_dim, num_heads, ff_dim, input_vocab_size, target_vocab_size, pe_input, pe_target)"]},{"cell_type":"markdown","id":"b630366b","metadata":{"id":"b630366b","papermill":{"duration":0.011196,"end_time":"2024-06-11T18:26:59.778172","exception":false,"start_time":"2024-06-11T18:26:59.766976","status":"completed"},"tags":[]},"source":["# Create the optimizer\n","The Adam optimizer is used with some changes in the parameters to better use the schedule for the learning rate. The Learning Rate Schedule is from an example of keras website."]},{"cell_type":"code","execution_count":null,"id":"a6ee98ae","metadata":{"execution":{"iopub.execute_input":"2024-06-11T18:26:59.803146Z","iopub.status.busy":"2024-06-11T18:26:59.802792Z","iopub.status.idle":"2024-06-11T18:26:59.814938Z","shell.execute_reply":"2024-06-11T18:26:59.814088Z"},"id":"a6ee98ae","papermill":{"duration":0.027192,"end_time":"2024-06-11T18:26:59.816910","exception":false,"start_time":"2024-06-11T18:26:59.789718","status":"completed"},"tags":[]},"outputs":[],"source":["# Create a class for a Learning Rate Schedule\n","class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n","  def __init__(self, d_model, warmup_steps=4000):\n","    super().__init__()\n","\n","    self.d_model = d_model\n","    self.d_model = tf.cast(self.d_model, tf.float32)\n","\n","    self.warmup_steps = warmup_steps\n","\n","  def __call__(self, step):\n","    step = tf.cast(step, dtype=tf.float32)\n","    arg1 = tf.math.rsqrt(step)\n","    arg2 = step * (self.warmup_steps ** -1.5)\n","\n","    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n","\n","# Create the learning rate\n","learning_rate = CustomSchedule(embed_dim)\n","\n","# Create the optimizer with Adam\n","optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"]},{"cell_type":"markdown","id":"c1f6e779","metadata":{"id":"c1f6e779","papermill":{"duration":0.01167,"end_time":"2024-06-11T18:26:59.840351","exception":false,"start_time":"2024-06-11T18:26:59.828681","status":"completed"},"tags":[]},"source":["# Create custom loss and accuracy\n","Definition of a custom loss and accuracy that improve the training performances working directly on the tokens, and therefore being more reliable to monitor."]},{"cell_type":"code","execution_count":null,"id":"241320f1","metadata":{"execution":{"iopub.execute_input":"2024-06-11T18:26:59.865136Z","iopub.status.busy":"2024-06-11T18:26:59.864799Z","iopub.status.idle":"2024-06-11T18:26:59.873773Z","shell.execute_reply":"2024-06-11T18:26:59.872861Z"},"id":"241320f1","papermill":{"duration":0.023827,"end_time":"2024-06-11T18:26:59.875632","exception":false,"start_time":"2024-06-11T18:26:59.851805","status":"completed"},"tags":[]},"outputs":[],"source":["K_VALUE = 0.97\n","max_sequence_len = 28\n","\n","# Define a custom loss function that works directly on tokens\n","def custom_masked_loss(label, pred):\n","    mask = label != 0\n","    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n","    loss = loss_object(label, pred)\n","\n","    a = tf.cast(tf.range(1, max_sequence_len + 1), tf.float32)\n","    constant_val = tf.constant(K_VALUE)\n","    final_array = tf.pow(constant_val, a)\n","\n","    mask = tf.cast(mask, dtype=loss.dtype)\n","    mask *= final_array\n","\n","    loss *= mask\n","\n","    return tf.reduce_sum(loss) / tf.reduce_sum(mask)\n","\n","# Define a custom metric that works directly on tokens\n","def masked_accuracy(label, pred):\n","    pred = tf.argmax(pred, axis=2)\n","    label = tf.cast(label, pred.dtype)\n","    match = label == pred\n","\n","    mask = label != 0\n","\n","    match = match & mask\n","\n","    match = tf.cast(match, dtype=tf.float32)\n","\n","    mask = tf.cast(mask, dtype=tf.float32)\n","\n","    return tf.reduce_sum(match) / tf.reduce_sum(mask)"]},{"cell_type":"markdown","id":"c1d17550","metadata":{"id":"c1d17550","papermill":{"duration":0.011321,"end_time":"2024-06-11T18:26:59.898370","exception":false,"start_time":"2024-06-11T18:26:59.887049","status":"completed"},"tags":[]},"source":["# Compile the model with callbacks and the necessary parameters"]},{"cell_type":"markdown","source":["The only callback used is the EarlyStopping monitoring the validaton loss. I tried also with `restore_best_weights=True`, but it performed worse with different networks.\n","\n"],"metadata":{"id":"XFlFk_UbKDJl"},"id":"XFlFk_UbKDJl"},{"cell_type":"code","execution_count":null,"id":"3c93787e","metadata":{"execution":{"iopub.execute_input":"2024-06-11T18:26:59.922743Z","iopub.status.busy":"2024-06-11T18:26:59.922383Z","iopub.status.idle":"2024-06-11T18:27:09.664585Z","shell.execute_reply":"2024-06-11T18:27:09.663179Z"},"id":"3c93787e","outputId":"e6cffb27-685b-4bf0-c5cb-d5e67465b01c","papermill":{"duration":9.757307,"end_time":"2024-06-11T18:27:09.667207","exception":false,"start_time":"2024-06-11T18:26:59.909900","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"transformer\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ transformer_encoder             │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,847,104</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ transformer_decoder             │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">8,013,568</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290,000</span> │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ transformer_encoder             │ ?                      │     \u001b[38;5;34m4,847,104\u001b[0m │\n","│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ transformer_decoder             │ ?                      │     \u001b[38;5;34m8,013,568\u001b[0m │\n","│ (\u001b[38;5;33mTransformerDecoder\u001b[0m)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_24 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │     \u001b[38;5;34m1,290,000\u001b[0m │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,150,672</span> (53.98 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,150,672\u001b[0m (53.98 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,150,672</span> (53.98 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m14,150,672\u001b[0m (53.98 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"}],"source":["# Set the batch size\n","BATCH_SIZE = 512\n","vocab_size = 10000\n","\n","# Create an EarlyStopping callback monitoring the val_accuracy\n","es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n","\n","src = tf.random.uniform((BATCH_SIZE, max_sequence_len), dtype=tf.int64, minval=0, maxval=vocab_size)\n","trg = tf.random.uniform((BATCH_SIZE, max_sequence_len), dtype=tf.int64, minval=0, maxval=vocab_size)\n","model((src,trg))\n","\n","# Compile the model\n","model.compile(optimizer=optimizer, loss=[custom_masked_loss], metrics=[masked_accuracy])\n","model.summary()\n","\n","# Remove the first element of each row\n","sliced_array = labels[:, 1:]\n","\n","# Append a column of zeros\n","ordered_sentences_shifted = np.hstack((sliced_array, np.zeros((sliced_array.shape[0], 1),dtype=int)))"]},{"cell_type":"markdown","source":["Fit the model (the number of epochs is set to an high number, but it always stops around 20 - 30 epochs with EarlyStopping)"],"metadata":{"id":"YQYNtjQXKrlZ"},"id":"YQYNtjQXKrlZ"},{"cell_type":"code","execution_count":null,"id":"ef92b31b","metadata":{"execution":{"iopub.execute_input":"2024-06-11T18:27:09.694252Z","iopub.status.busy":"2024-06-11T18:27:09.693915Z","iopub.status.idle":"2024-06-11T19:06:31.118346Z","shell.execute_reply":"2024-06-11T19:06:31.117192Z"},"id":"ef92b31b","outputId":"46bd3bce-0428-4825-c98d-b7855cdb4dac","papermill":{"duration":2361.440637,"end_time":"2024-06-11T19:06:31.120798","exception":false,"start_time":"2024-06-11T18:27:09.680161","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/75\n"]},{"name":"stderr","output_type":"stream","text":["WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","I0000 00:00:1718130536.702608      78 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","W0000 00:00:1718130536.787702      78 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432ms/step - loss: 8.7485 - masked_accuracy: 0.0584"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1718130703.655397      79 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 467ms/step - loss: 8.7468 - masked_accuracy: 0.0585 - val_loss: 6.6719 - val_masked_accuracy: 0.2241\n","Epoch 2/75\n","\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 278ms/step - loss: 6.1456 - masked_accuracy: 0.2621 - val_loss: 4.7105 - val_masked_accuracy: 0.3700\n","Epoch 3/75\n","\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 277ms/step - loss: 4.4126 - masked_accuracy: 0.3968 - val_loss: 3.3065 - val_masked_accuracy: 0.5228\n","Epoch 4/75\n","\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 278ms/step - loss: 3.1531 - masked_accuracy: 0.5352 - val_loss: 2.2867 - val_masked_accuracy: 0.6391\n","Epoch 5/75\n","\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 278ms/step - loss: 2.2455 - masked_accuracy: 0.6353 - val_loss: 1.6743 - val_masked_accuracy: 0.7019\n","Epoch 6/75\n","\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 278ms/step - loss: 1.6675 - masked_accuracy: 0.6950 - val_loss: 1.3101 - val_masked_accuracy: 0.7384\n","Epoch 7/75\n","\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 278ms/step - loss: 1.3258 - masked_accuracy: 0.7298 - val_loss: 1.1638 - val_masked_accuracy: 0.7534\n","Epoch 8/75\n","\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 278ms/step - loss: 1.1345 - masked_accuracy: 0.7502 - val_loss: 1.0316 - val_masked_accuracy: 0.7705\n","Epoch 9/75\n","\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 278ms/step - loss: 1.0156 - masked_accuracy: 0.7657 - val_loss: 1.0226 - val_masked_accuracy: 0.7713\n","Epoch 10/75\n","\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 278ms/step - loss: 0.9377 - masked_accuracy: 0.7772 - val_loss: 0.9396 - val_masked_accuracy: 0.7831\n","Epoch 11/75\n","\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 278ms/step - loss: 0.8732 - masked_accuracy: 0.7875 - val_loss: 0.9087 - val_masked_accuracy: 0.7896\n","Epoch 12/75\n","\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 278ms/step - loss: 0.7895 - masked_accuracy: 0.8027 - val_loss: 0.8720 - val_masked_accuracy: 0.8002\n","Epoch 13/75\n","\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 278ms/step - loss: 0.7075 - masked_accuracy: 0.8183 - val_loss: 0.8360 - val_masked_accuracy: 0.8042\n","Epoch 14/75\n","\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 278ms/step - loss: 0.6409 - masked_accuracy: 0.8315 - val_loss: 0.8273 - val_masked_accuracy: 0.8137\n","Epoch 15/75\n","\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 278ms/step - loss: 0.5815 - masked_accuracy: 0.8440 - val_loss: 0.8310 - val_masked_accuracy: 0.8164\n","Epoch 16/75\n","\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 278ms/step - loss: 0.5358 - masked_accuracy: 0.8540 - val_loss: 0.8276 - val_masked_accuracy: 0.8184\n","Epoch 17/75\n","\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 278ms/step - loss: 0.4934 - masked_accuracy: 0.8636 - val_loss: 0.8277 - val_masked_accuracy: 0.8227\n","Epoch 18/75\n","\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 278ms/step - loss: 0.4545 - masked_accuracy: 0.8728 - val_loss: 0.8274 - val_masked_accuracy: 0.8236\n","Epoch 19/75\n","\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 278ms/step - loss: 0.4231 - masked_accuracy: 0.8799 - val_loss: 0.8476 - val_masked_accuracy: 0.8223\n","Epoch 19: early stopping\n"]}],"source":["# Fit the model on the training set\n","history = model.fit(x = (Xtrain, ytrain),\n","                    y = ordered_sentences_shifted,\n","                    batch_size = BATCH_SIZE,\n","                    epochs=75,\n","                    callbacks=[es],\n","                    validation_split=0.1)"]},{"cell_type":"markdown","source":["Save the weights"],"metadata":{"id":"e2PYYiV2LEOu"},"id":"e2PYYiV2LEOu"},{"cell_type":"code","execution_count":null,"id":"e0bd176e","metadata":{"execution":{"iopub.execute_input":"2024-06-11T19:06:32.382598Z","iopub.status.busy":"2024-06-11T19:06:32.382208Z","iopub.status.idle":"2024-06-11T19:06:33.157802Z","shell.execute_reply":"2024-06-11T19:06:33.157027Z"},"papermill":{"duration":1.382188,"end_time":"2024-06-11T19:06:33.160176","exception":false,"start_time":"2024-06-11T19:06:31.777988","status":"completed"},"tags":[],"id":"e0bd176e"},"outputs":[],"source":["model.save_weights(f'weights_tancredi_bosi.weights.h5')"]},{"cell_type":"markdown","id":"b604e920","metadata":{"id":"b604e920","papermill":{"duration":0.669723,"end_time":"2024-06-11T19:06:34.429102","exception":false,"start_time":"2024-06-11T19:06:33.759379","status":"completed"},"tags":[]},"source":["# Metrics"]},{"cell_type":"markdown","id":"5a3b5f13","metadata":{"id":"5a3b5f13","papermill":{"duration":0.600845,"end_time":"2024-06-11T19:06:35.637094","exception":false,"start_time":"2024-06-11T19:06:35.036249","status":"completed"},"tags":[]},"source":["Let s be the source string and p your prediction. The quality of the results will be measured according to the following metric:\n","\n","1.  look for the longest substring w between s and p\n","2.  compute |w|/max(|s|,|p|)\n","\n","If the match is exact, the score is 1.\n","\n","When computing the score, you should NOT consider the start and end tokens.\n","\n"]},{"cell_type":"markdown","id":"c9fd5dbf","metadata":{"id":"c9fd5dbf","papermill":{"duration":0.659326,"end_time":"2024-06-11T19:06:36.899545","exception":false,"start_time":"2024-06-11T19:06:36.240219","status":"completed"},"tags":[]},"source":["The longest common substring can be computed with the SequenceMatcher function of difflib, that allows a simple definition of our metric."]},{"cell_type":"code","source":["def score(s,p):\n","  match = SequenceMatcher(None, s, p).find_longest_match()\n","\n","  return (match.size/max(len(p),len(s)))"],"metadata":{"id":"JUrCxSR9LPvM"},"id":"JUrCxSR9LPvM","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The score is computed on the test set that is already shuffled. I decided to compute the score on 5k sentences to have a robust value, and I calculated it in batches of 1k sentences to make the process faster."],"metadata":{"id":"53bo1B9LLTiJ"},"id":"53bo1B9LLTiJ"},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T19:06:38.107820Z","iopub.status.busy":"2024-06-11T19:06:38.107383Z","iopub.status.idle":"2024-06-11T19:09:02.652578Z","shell.execute_reply":"2024-06-11T19:09:02.651487Z"},"outputId":"a8481557-3946-4406-bc02-6710da2fe829","papermill":{"duration":145.153998,"end_time":"2024-06-11T19:09:02.654731","exception":false,"start_time":"2024-06-11T19:06:37.500733","status":"completed"},"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718181541696,"user_tz":-120,"elapsed":159532,"user":{"displayName":"Rachele Matassini","userId":"13630989281297100794"}},"id":"Y6-js3ZZmyU0"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (1000, 8, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","Computed: 1000; Score: 0.5046563162023712 \n","\n","-------------------------------\n","\n","Computed: 2000; Score: 0.5009717488009906 \n","\n","-------------------------------\n","\n","Computed: 3000; Score: 0.49879653211544805 \n","\n","-------------------------------\n","\n","Computed: 4000; Score: 0.49947771227995613 \n","\n","-------------------------------\n","\n","Computed: 5000; Score: 0.5007268192200046 \n","\n","-------------------------------\n","\n","\n","AVERAGE SCORE OVER 5000 ELEMENTS: 0.5007268192200035\n"]}],"source":["# Create a function that decodes the sentences in order to be able to make predictions\n","def decode_sentence(input_sentences, max_length=28):\n","    batch_size = tf.shape(input_sentences)[0]\n","    encoder_input = input_sentences\n","    decoded_indexes = [[3] for _ in range(batch_size)]\n","\n","    for i in range(1, max_length):\n","        decoder_input = tf.convert_to_tensor(decoded_indexes)\n","        predictions = np.array(model((np.array(encoder_input), np.array(decoder_input)), training=False))\n","        predictions = predictions[:, -1, :]\n","        for j in range(batch_size):\n","            best_index = np.argmax(predictions[j])\n","            decoded_indexes[j].append(best_index)\n","\n","    return decoded_indexes\n","\n","# Load the test set (only 'total' sentences)\n","detokenizer = TextDetokenizer(tokenizer)\n","batch_size = 1000\n","total = 5000\n","testset = DataGenerator(shuffled_data[220000:], batch_size=total)\n","shuffled_sentences_test, original_sentences_test = testset.__getitem__(0)\n","\n","# Make predictions of all the test set sentences\n","# and append the intermediate results in the list 'all_scores'\n","all_scores = []\n","for i in range(total//batch_size):\n","    shuffled_sentences = shuffled_sentences_test[i*batch_size:(i+1)*batch_size]\n","    original_sentences = original_sentences_test[i*batch_size:(i+1)*batch_size]\n","    translated_sentences = decode_sentence(shuffled_sentences)\n","\n","    detokenized_predictions = detokenizer(translated_sentences)\n","    detokenized_labels = detokenizer(original_sentences)\n","\n","    all_scores += [score(single_original.replace(\"<start>\", \"\").replace(\"<end>\", \"\").replace(\" <comma>\", \",\").strip(), single_translated.replace(\"<start>\", \"\").replace(\"<end>\", \"\").replace(\" <comma>\", \",\").strip()) for single_original, single_translated in zip(detokenized_labels, detokenized_predictions)]\n","    print(f\"\\nComputed: {len(all_scores)}; Score: {np.mean(all_scores)} \\n\")\n","    print('-------------------------------')\n","\n","# Print the average score over all the test set 'total' elements\n","print('\\n')\n","print('AVERAGE SCORE OVER', total, 'ELEMENTS:', sum(all_scores)/len(all_scores))"],"id":"Y6-js3ZZmyU0"},{"cell_type":"code","source":["plt.hist(all_scores, color='yellow', edgecolor='black', bins=10)\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":430},"id":"zEEcqUIaetDT","executionInfo":{"status":"ok","timestamp":1718179889244,"user_tz":-120,"elapsed":531,"user":{"displayName":"Rachele Matassini","userId":"13630989281297100794"}},"outputId":"5a742c9d-b3d7-4377-97a5-c4d20b2c7cbf"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"id":"zEEcqUIaetDT"}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30733,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":2758.962217,"end_time":"2024-06-11T19:09:20.719479","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-06-11T18:23:21.757262","version":"2.5.0"}},"nbformat":4,"nbformat_minor":5}